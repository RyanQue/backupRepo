{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf983890",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9cae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# setting\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "\n",
    "# ===================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f479ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f808da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d15b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility (global setting)\n",
    "\n",
    "def seed_everything(seed=12):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a63f06",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eaac25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('preprocessedtrain_deep.csv',\n",
    "                      index_col = 0,\n",
    "                      converters = {'reviewTexttokenized': eval,\n",
    "                                    'summarytokenized': eval}\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8200d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTextCharCount</th>\n",
       "      <th>overlapScore</th>\n",
       "      <th>summaryCharCount</th>\n",
       "      <th>reviewTextUpperCount</th>\n",
       "      <th>summaryUpperCount</th>\n",
       "      <th>reviewTexttokenized</th>\n",
       "      <th>summarytokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>plot storyline : 5 starsthis novel accomplishe...</td>\n",
       "      <td>3 1/4 stars</td>\n",
       "      <td>3370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>[plot, storyline, 5, starsthis, novel, accompl...</td>\n",
       "      <td>[3, 1/4, star]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>i did not like how el ended this one . i do no...</td>\n",
       "      <td>it was going great , then just ... ended</td>\n",
       "      <td>363</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[not, like, how, al, end, one, not, want, ruin...</td>\n",
       "      <td>[go, great, just, ..., end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>i love how old fashioned this family is - they...</td>\n",
       "      <td>loved all 4!</td>\n",
       "      <td>287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[love, how, old, fashion, family, see, someone...</td>\n",
       "      <td>[love, all, 4, !]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                         reviewText  \\\n",
       "0       3  plot storyline : 5 starsthis novel accomplishe...   \n",
       "1       3  i did not like how el ended this one . i do no...   \n",
       "2       5  i love how old fashioned this family is - they...   \n",
       "\n",
       "                                    summary  reviewTextCharCount  \\\n",
       "0                               3 1/4 stars                 3370   \n",
       "1  it was going great , then just ... ended                  363   \n",
       "2                              loved all 4!                  287   \n",
       "\n",
       "   overlapScore  summaryCharCount  reviewTextUpperCount  summaryUpperCount  \\\n",
       "0      0.000000                11                    72                  1   \n",
       "1      0.428571                39                     8                  1   \n",
       "2      0.000000                12                     4                  8   \n",
       "\n",
       "                                 reviewTexttokenized  \\\n",
       "0  [plot, storyline, 5, starsthis, novel, accompl...   \n",
       "1  [not, like, how, al, end, one, not, want, ruin...   \n",
       "2  [love, how, old, fashion, family, see, someone...   \n",
       "\n",
       "              summarytokenized  \n",
       "0               [3, 1/4, star]  \n",
       "1  [go, great, just, ..., end]  \n",
       "2            [love, all, 4, !]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cc9fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxLengthReview 1270\n",
      "MaxLengthSummary 17\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "MaxLengthReview = 0\n",
    "MaxLengthSummary = 0\n",
    "\n",
    "for row in dataset['reviewTexttokenized']:\n",
    "    counter.update(row)\n",
    "    if len(row) > MaxLengthReview:\n",
    "        MaxLengthReview = len(row)\n",
    "\n",
    "for row in dataset['summarytokenized']:\n",
    "    counter.update(row)\n",
    "    if len(row) > MaxLengthSummary:\n",
    "        MaxLengthSummary = len(row)\n",
    "        \n",
    "print('MaxLengthReview', MaxLengthReview)\n",
    "print('MaxLengthSummary',MaxLengthSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9be4ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLovevectors = GloVe(name='6B',\n",
    "                     dim=200,\n",
    "                     cache='D:/program files/jupyter notebook/usyd/6850/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0748ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the config in the model and training\n",
    "class Config():\n",
    "\n",
    "    #embedding config\n",
    "       #how many number of words in glove embedding dict\n",
    "       #if error occurs - change 400001 to 400000\n",
    "    embed_vocab_num = 400001\n",
    "    \n",
    "    embed_dim = 200 # dimension of the embedding\n",
    "    embed_trainable = False # whether train(fine tune) the weight of embedding\n",
    "    \n",
    "    #Bi-LSTM config\n",
    "    hidden_size = 100\n",
    "    output_size = 1\n",
    "    dropout = 0.1\n",
    "    lstm_layers = 1\n",
    "    \n",
    "    # CNN config\n",
    "    kernel_num = 32 # number of kernels\n",
    "    kernel_size = [2,3,4] # CNN filter size - similar to n-gram\n",
    "    \n",
    "    max_seq_len_review = MaxLengthReview\n",
    "    max_seq_len_summary = MaxLengthSummary\n",
    "    \n",
    "    batch_size = 128\n",
    "    epoch = 12\n",
    "    \n",
    "    learning_rate = 0.05\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9212e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Token2EmbedIndex(row):\n",
    "    \"\"\"\n",
    "    replace the token with the index in the glove dictionary\n",
    "    if the word cannot be located in the dictionary, it will be assigned\n",
    "    with the same index as <unk> - the last key in the dictionary\n",
    "    \"\"\"\n",
    "    transferedList = []\n",
    "    for token in row:\n",
    "        try:\n",
    "            transferedList.append(GLovevectors.stoi[token])\n",
    "        except KeyError:\n",
    "            transferedList.append(400000)\n",
    "    return transferedList\n",
    "\n",
    "dataset['reviewTexttokenized'] = dataset['reviewTexttokenized'].apply(Token2EmbedIndex)\n",
    "dataset['summarytokenized'] = dataset['summarytokenized'].apply(Token2EmbedIndex)\n",
    "\n",
    "def paddingfunc(row, length):\n",
    "    \"\"\"padding the list to the same length with 0\"\"\"\n",
    "    if len(row) == length:\n",
    "        pass\n",
    "    elif len(row) < length:\n",
    "        for i in range(length - len(row)):\n",
    "            row.append(0)\n",
    "    elif len(row) > length:\n",
    "        row = row[:length]\n",
    "    return np.array(row)\n",
    "\n",
    "dataset['reviewTexttokenized'] = dataset['reviewTexttokenized'].apply(lambda x: paddingfunc(x,length = config.max_seq_len_review))\n",
    "dataset['summarytokenized'] = dataset['summarytokenized'].apply(lambda x: paddingfunc(x,length = config.max_seq_len_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443221aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown embedding\n",
    "GLovevectors.vectors = torch.cat((GLovevectors.vectors,GLovevectors.vectors.mean(axis=0).unsqueeze(0)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e0a8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ally = dataset[['rating']].apply(lambda x:x-1)\n",
    "allX = dataset[['reviewTexttokenized',\n",
    "                'summarytokenized']]\n",
    "\n",
    "# splitting the test\n",
    "## =============\n",
    "X_tr_va, X_test, y_tr_va, y_test = train_test_split(allX,\n",
    "                                                    ally,\n",
    "                                                    test_size=1/6,\n",
    "                                                    random_state=12,\n",
    "                                                    stratify=ally)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tr_va,\n",
    "                                                      y_tr_va,\n",
    "                                                      test_size=1/5,\n",
    "                                                      random_state=12,\n",
    "                                                      stratify=y_tr_va)\n",
    "\n",
    "#X_tr_va.reset_index(drop = True, inplace = True)\n",
    "#X_test.reset_index(drop = True, inplace = True)\n",
    "#y_tr_va.reset_index(drop = True, inplace = True)\n",
    "#y_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "## the rest will be cross validation - use stratified kfold\n",
    "#SKF = StratifiedKFold(n_splits = 5, random_state = 12, shuffle  = True)\n",
    "#DFlist = []\n",
    "#for train_index, valid_index in SKF.split(X_tr_va, y_tr_va):\n",
    "#    X_train, X_valid = X_tr_va.iloc[train_index], X_tr_va.iloc[valid_index]\n",
    "#    y_train, y_valid = y_tr_va.iloc[train_index], y_tr_va.iloc[valid_index]\n",
    "#    \n",
    "#    DFlist.append((X_train, X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1364b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFlist[1][1].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37cdc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = allX.join(ally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9d88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = torch.tensor(ally.values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a263880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_importance_weights(label_array):\n",
    "    uniq = torch.unique(label_array)\n",
    "    num_examples = label_array.size(0)\n",
    "\n",
    "    m = torch.zeros(uniq.shape[0])\n",
    "\n",
    "    for i, t in enumerate(torch.arange(torch.min(uniq), torch.max(uniq))):\n",
    "        m_k = torch.max(torch.tensor([label_array[label_array > t].size(0), \n",
    "                                      num_examples - label_array[label_array > t].size(0)]))\n",
    "        m[i] = torch.sqrt(m_k.float())\n",
    "\n",
    "    imp = m/torch.max(m)\n",
    "    return imp\n",
    "\n",
    "imp = task_importance_weights(ratings)\n",
    "imp = imp[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9d9de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "class ratingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, review, summary, rating):\n",
    "\n",
    "        df = traindata\n",
    "        self.rating = rating\n",
    "        self.review = review\n",
    "        self.summary = summary\n",
    "\n",
    "    def __getitem__(self, index):      \n",
    "        review = torch.Tensor(self.review.iloc[index]).long()\n",
    "        summary= torch.Tensor(self.summary.iloc[index]).long()\n",
    "        label = self.rating.iloc[index]\n",
    "        levels = [1]*label + [0]*(5 - 1 - label) #encoding the target\n",
    "        levels = torch.tensor(levels, dtype=torch.float32)\n",
    "\n",
    "        return review, summary, label, levels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.rating.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a68ec8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ratingDataset(X_train['reviewTexttokenized'],\n",
    "                              X_train['summarytokenized'],\n",
    "                              y_train['rating'])\n",
    "\n",
    "valid_dataset = ratingDataset(X_valid['reviewTexttokenized'],\n",
    "                              X_valid['summarytokenized'],\n",
    "                              y_valid['rating'])\n",
    "\n",
    "test_dataset = ratingDataset(X_test['reviewTexttokenized'],\n",
    "                             X_test['summarytokenized'],\n",
    "                             y_test['rating'])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=config.batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=config.batch_size,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=config.batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e379ac",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "522d5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_TextCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BiLSTM_TextCNN, self).__init__()\n",
    "        #embedding layer\n",
    "        \n",
    "        self.embedding = nn.Embedding(config.embed_vocab_num, config.embed_dim)\n",
    "        self.embedding.weight.data.copy_(GLovevectors.vectors)\n",
    "        self.embedding.weight.data.requires_grad = config.embed_trainable\n",
    "        \n",
    "        # Bi-LSTM architecture\n",
    "        \n",
    "        self.BiLSTM = nn.LSTM(input_size = config.embed_dim,\n",
    "                              hidden_size = config.hidden_size,\n",
    "                              num_layers = config.lstm_layers,\n",
    "                              bidirectional=True,\n",
    "                              # first dimension is batch size\n",
    "                              batch_first=True,\n",
    "                              dropout = config.dropout                             \n",
    "                             )\n",
    "        # output dim (batch, sentense length, hidden size * 2)\n",
    "        \n",
    "        # CNN architecture after Bi LSTM\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = config.hidden_size*2,\n",
    "                      out_channels = config.kernel_num,\n",
    "                      kernel_size = config.kernel_size[0]),\n",
    "            nn.ReLU(),#activate\n",
    "            nn.MaxPool1d(config.max_seq_len_review - config.kernel_size[0] + 1) #(n-2+1)*1.\n",
    "        )\n",
    "        \n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = config.hidden_size*2,\n",
    "                      out_channels = config.kernel_num,\n",
    "                      kernel_size = config.kernel_size[1]),\n",
    "            nn.ReLU(),#activate\n",
    "            nn.MaxPool1d(config.max_seq_len_review - config.kernel_size[1] + 1) #(n-3+1)*1.\n",
    "        )\n",
    "        \n",
    "        self.conv_block_4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = config.hidden_size*2,\n",
    "                      out_channels = config.kernel_num,\n",
    "                      kernel_size = config.kernel_size[2]),\n",
    "            nn.ReLU(),#activate\n",
    "            nn.MaxPool1d(config.max_seq_len_review - config.kernel_size[2] + 1) #(n-4+1)*1.\n",
    "        )\n",
    "        \n",
    "        # CNN architecture for summary\n",
    "        #  ================================\n",
    "        \n",
    "        self.conv_block_2_s = nn.Sequential(\n",
    "            nn.Conv1d(config.embed_dim, config.kernel_num, config.kernel_size[0]),\n",
    "            nn.ReLU(),#activate\n",
    "            nn.MaxPool1d(config.max_seq_len_summary - config.kernel_size[0] + 1) #(n-2+1)*1.\n",
    "        )\n",
    "        \n",
    "        self.conv_block_3_s = nn.Sequential(\n",
    "            nn.Conv1d(config.embed_dim, config.kernel_num, config.kernel_size[1]),\n",
    "            nn.ReLU(),#activate\n",
    "            nn.MaxPool1d(config.max_seq_len_summary - config.kernel_size[1] + 1) #(n-3+1)*1.\n",
    "        )\n",
    "        \n",
    "        self.conv_block_4_s = nn.Sequential(\n",
    "            nn.Conv1d(config.embed_dim, config.kernel_num, config.kernel_size[2]),\n",
    "            nn.ReLU(),#activate\n",
    "            nn.MaxPool1d(config.max_seq_len_summary - config.kernel_size[2] + 1) #(n-4+1)*1.\n",
    "        )\n",
    "        # classify layer =============================\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "        # 2 cnn + 2 individual input\n",
    "        self.fc = nn.Linear(config.kernel_num * len(config.kernel_size)*2, 1) #+2\n",
    "        self.linear_1_bias = nn.Parameter(torch.zeros(5-1).float())\n",
    "        \n",
    "    def forward(self, review, summary):\n",
    "        # shape:\n",
    "        # review = batchsize , max_lengthreview\n",
    "        # summary = batchsize , max_lengthsummary\n",
    "        # 2 Uppers = batchsize , 1\n",
    "        \n",
    "        # (bi lstm + cnn) for reviewtokenized\n",
    "            # Hidden and cell state definion\n",
    "        #h0 = torch.zeros((2*config.lstm_layers, config.batch_size, config.hidden_size))\n",
    "        #c0 = torch.zeros((2*config.lstm_layers, config.batch_size, config.hidden_size))\n",
    "                # normal distributed init\n",
    "        #torch.nn.init.xavier_normal_(h0)  \n",
    "        #torch.nn.init.xavier_normal_(c0)\n",
    "            # model\n",
    "        embedded_review = self.embedding(review) # embedded = batch, length, embedd dim\n",
    "        packed_output, (hidden, cell) = self.BiLSTM(embedded_review)# ,(h0,c0)\n",
    "        # packed_output = batch , max length , 2* hidden size\n",
    "        # packed_output = packed_output.unsqueeze(1)\n",
    "        packed_output = packed_output.transpose(2,1)\n",
    "        conv_block_2 = self.conv_block_2(packed_output)\n",
    "            # input = batch , max length , 2* hidden size\n",
    "            # conv1dout = batch, kernel num, max length\n",
    "            #conv_block.shape: (batch_size, kernel_num, 1)\n",
    "        conv_block_3 = self.conv_block_3(packed_output)\n",
    "        conv_block_4 = self.conv_block_4(packed_output)\n",
    "        \n",
    "        out_review = torch.cat((conv_block_2.squeeze(2),\n",
    "                                conv_block_3.squeeze(2),\n",
    "                                conv_block_4.squeeze(2)), 1)\n",
    "        \n",
    "        # cnn for summarytokenized\n",
    "\n",
    "        embedded_summary = self.embedding(summary)\n",
    "        # embedded_summary = embedded_summary.unsqueeze(1)\n",
    "        embedded_summary = embedded_summary.transpose(2,1)\n",
    "        \n",
    "        conv_block_2_s = self.conv_block_2_s(embedded_summary)            \n",
    "        conv_block_3_s = self.conv_block_3_s(embedded_summary)\n",
    "        conv_block_4_s = self.conv_block_4_s(embedded_summary)\n",
    "        \n",
    "        out_summary = torch.cat((conv_block_2_s.squeeze(2),\n",
    "                                 conv_block_3_s.squeeze(2),\n",
    "                                 conv_block_4_s.squeeze(2)), 1)\n",
    "        \n",
    "        #print(out_review,'=='*10, out_summary,'=='*10, Upperreview,'=='*10, Uppersummary)\n",
    "        #print(Upperreview.shape)\n",
    "        #out_review.flatten()\n",
    "        #out_summary.flatten()\n",
    "        \n",
    "        concatfeature = torch.cat((out_review, out_summary),1) # 256*48 256*48 256*1 256*1\n",
    "        \n",
    "        # full connect and softmax\n",
    "        x = self.dropout(concatfeature)\n",
    "        logits = self.fc(x)\n",
    "        logits = logits + self.linear_1_bias\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return logits, probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9b5343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(logits, levels, imp):\n",
    "    val = (-torch.sum((F.logsigmoid(logits)*levels\n",
    "                      + (F.logsigmoid(logits) - logits)*(1-levels))*imp,\n",
    "           dim=1))\n",
    "    return torch.mean(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd8dea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_TextCNN(config = Config())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e632b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d143035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_F1_score(model, data_loader, device):\n",
    "    f1score, num_examples = 0, 0\n",
    "    targetlist = []\n",
    "    predictedlist = []\n",
    "    for i, (review,summary, targets, levels) in enumerate(data_loader):\n",
    "\n",
    "        logits, probas = model(review,summary)\n",
    "        predict_levels = probas > 0.5\n",
    "        predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "        targetlist.extend(targets.tolist())\n",
    "        predictedlist.extend(predicted_labels.tolist())\n",
    "    \n",
    "    f1Score = f1_score(predictedlist, targetlist, average = 'weighted')\n",
    "    return f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab8b8e32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/012 | Batch 0000/0046 | Cost: 2.6058\n",
      "f1: | Current Valid: 0.3125 Ep. 0 | Best Valid : 0.3125 Ep. 0\n",
      "Time elapsed: 8.28 min\n",
      "Epoch: 002/012 | Batch 0000/0046 | Cost: 2.7897\n",
      "f1: | Current Valid: 0.4363 Ep. 1 | Best Valid : 0.4363 Ep. 1\n",
      "Time elapsed: 16.63 min\n",
      "Epoch: 003/012 | Batch 0000/0046 | Cost: 1.5428\n",
      "f1: | Current Valid: 0.4337 Ep. 2 | Best Valid : 0.4363 Ep. 1\n",
      "Time elapsed: 24.94 min\n",
      "Epoch: 004/012 | Batch 0000/0046 | Cost: 1.3170\n",
      "f1: | Current Valid: 0.4062 Ep. 3 | Best Valid : 0.4363 Ep. 1\n",
      "Time elapsed: 33.34 min\n",
      "Epoch: 005/012 | Batch 0000/0046 | Cost: 1.5066\n",
      "f1: | Current Valid: 0.4334 Ep. 4 | Best Valid : 0.4363 Ep. 1\n",
      "Time elapsed: 41.74 min\n",
      "Epoch: 006/012 | Batch 0000/0046 | Cost: 1.1342\n",
      "f1: | Current Valid: 0.4482 Ep. 5 | Best Valid : 0.4482 Ep. 5\n",
      "Time elapsed: 49.12 min\n",
      "Epoch: 007/012 | Batch 0000/0046 | Cost: 1.6796\n",
      "f1: | Current Valid: 0.4217 Ep. 6 | Best Valid : 0.4482 Ep. 5\n",
      "Time elapsed: 56.60 min\n",
      "Epoch: 008/012 | Batch 0000/0046 | Cost: 1.6688\n",
      "f1: | Current Valid: 0.4209 Ep. 7 | Best Valid : 0.4482 Ep. 5\n",
      "Time elapsed: 64.06 min\n",
      "Epoch: 009/012 | Batch 0000/0046 | Cost: 1.1996\n",
      "f1: | Current Valid: 0.4097 Ep. 8 | Best Valid : 0.4482 Ep. 5\n",
      "Time elapsed: 71.59 min\n",
      "Epoch: 010/012 | Batch 0000/0046 | Cost: 0.8890\n",
      "f1: | Current Valid: 0.4159 Ep. 9 | Best Valid : 0.4482 Ep. 5\n",
      "Time elapsed: 79.20 min\n",
      "Epoch: 011/012 | Batch 0000/0046 | Cost: 1.2377\n",
      "f1: | Current Valid: 0.4146 Ep. 10 | Best Valid : 0.4482 Ep. 5\n",
      "Time elapsed: 86.88 min\n",
      "Epoch: 012/012 | Batch 0000/0046 | Cost: 0.8478\n",
      "f1: | Current Valid: 0.3978 Ep. 11 | Best Valid : 0.4482 Ep. 5\n",
      "Time elapsed: 94.66 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTM_TextCNN(\n",
       "  (embedding): Embedding(400001, 200)\n",
       "  (BiLSTM): LSTM(200, 100, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv1d(200, 16, kernel_size=(2,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=1269, stride=1269, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_3): Sequential(\n",
       "    (0): Conv1d(200, 16, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=1268, stride=1268, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_4): Sequential(\n",
       "    (0): Conv1d(200, 16, kernel_size=(4,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=1267, stride=1267, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2_s): Sequential(\n",
       "    (0): Conv1d(200, 16, kernel_size=(2,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_3_s): Sequential(\n",
       "    (0): Conv1d(200, 16, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_4_s): Sequential(\n",
       "    (0): Conv1d(200, 16, kernel_size=(4,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=14, stride=14, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=96, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_f1, best_epoch = 0, -1\n",
    "for epoch in range(config.epoch): \n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (review,summary, targets, levels) in enumerate(train_loader):\n",
    "\n",
    "        # FORWARD AND BACK PROP\n",
    "        logits, probas = model(review,summary)\n",
    "        cost = cost_fn(logits, levels, imp)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        # UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "\n",
    "        # LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f'\n",
    "                 % (epoch+1, config.epoch , batch_idx,\n",
    "                     len(train_dataset)//config.batch_size, cost))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        valid_f1 = compute_F1_score(model, valid_loader,'cpu')\n",
    "        #valid_mae, valid_mse = compute_mae_and_mse(model, valid_loader, 'cpu')\n",
    "\n",
    "    if valid_f1 > best_f1:\n",
    "        best_f1, best_epoch = valid_f1, epoch\n",
    "        ########## SAVE MODEL #############\n",
    "        torch.save(model.state_dict(), os.path.join(r\"D:/program files/jupyter notebook/usyd\\6850/Final Version/\", 'best_model.pt'))\n",
    "\n",
    "\n",
    "    s = 'f1: | Current Valid: %.4f Ep. %d | Best Valid : %.4f Ep. %d' % (\n",
    "        valid_f1, epoch, best_f1, best_epoch)\n",
    "    print(s)\n",
    "\n",
    "    s = 'Time elapsed: %.2f min' % ((time.time() - start_time)/60)\n",
    "    print(s)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "137e1a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: | Train: 0.5921 | Valid: 0.3978 | Test: 0.3924\n",
      "Total Training Time: 97.97 min\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False):  # save memory during inference\n",
    "\n",
    "    train_f1 = compute_F1_score(model, train_loader,'cpu')\n",
    "    valid_f1 = compute_F1_score(model, valid_loader,'cpu')\n",
    "    test_f1 = compute_F1_score(model, test_loader,'cpu')\n",
    "\n",
    "    s = 'f1 score: | Train: %.4f | Valid: %.4f | Test: %.4f' % (\n",
    "        train_f1, \n",
    "        valid_f1, \n",
    "        test_f1, )\n",
    "    print(s)\n",
    "\n",
    "s = 'Total Training Time: %.2f min' % ((time.time() - start_time)/60)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9261ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: | Best Train: 0.6291 | Best Valid: 0.4482 | Best Test: 0.4379\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model\n",
    "model.load_state_dict(torch.load(r\"D:/program files/jupyter notebook/usyd/6850/Final Version/best_model.pt\"))####\n",
    "model.eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_f1 = compute_F1_score(model, train_loader,\n",
    "                                               device='cpu')\n",
    "    valid_f1 = compute_F1_score(model, valid_loader,\n",
    "                                               device='cpu')\n",
    "    test_f1 = compute_F1_score(model, test_loader,\n",
    "                                             device='cpu')\n",
    "\n",
    "    s = 'f1: | Best Train: %.4f | Best Valid: %.4f | Best Test: %.4f' % (\n",
    "        train_f1,\n",
    "        valid_f1,\n",
    "        test_f1)\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85d11e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "all_pred = []\n",
    "all_probas = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_idx, (review,summary, targets, levels) in enumerate(test_loader):\n",
    "        \n",
    "\n",
    "        logits, probas = model(review,summary)\n",
    "        all_probas.append(probas)\n",
    "        predict_levels = probas > 0.5\n",
    "        predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "        lst = [str(int(i)) for i in predicted_labels]\n",
    "        all_pred.extend(lst)\n",
    "\n",
    "torch.save(torch.cat(all_probas).to(torch.device('cpu')),r\"D:/program files/jupyter notebook/usyd/6850/Final Version/test_allprobas.tensor\")####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaf86d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.42733333333333334\n"
     ]
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(data = all_pred, columns = ['rating'])\n",
    "test_pred['rating'] = test_pred['rating'].apply(lambda x: int(x))\n",
    "print('accuracy:')\n",
    "print((test_pred['rating'].values == y_test['rating'].values).sum()/1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0b6a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40190407876456397"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_pred['rating'].values, y_test['rating'].values, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29215061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission\n",
    "subdataset = pd.read_csv('preprocessedtest_deep.csv',\n",
    "                         index_col = 0,\n",
    "                         converters = {'reviewTexttokenized': eval,\n",
    "                                       'summarytokenized': eval})\n",
    "\n",
    "subdataset['reviewTexttokenized'] = subdataset['reviewTexttokenized'].apply(Token2EmbedIndex)\n",
    "subdataset['summarytokenized'] = subdataset['summarytokenized'].apply(Token2EmbedIndex)\n",
    "\n",
    "subdataset['reviewTexttokenized'] = subdataset['reviewTexttokenized'].apply(lambda x: paddingfunc(x,length = config.max_seq_len_review))\n",
    "subdataset['summarytokenized'] = subdataset['summarytokenized'].apply(lambda x: paddingfunc(x,length = config.max_seq_len_summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d678b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = subdataset[['reviewTexttokenized','summarytokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f28103d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewTexttokenized</th>\n",
       "      <th>summarytokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[181, 5990, 36, 1089, 1465, 1465, 1594, 181, 4...</td>\n",
       "      <td>[1257, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[117, 539, 1250, 413, 2025, 96, 45324, 32173, ...</td>\n",
       "      <td>[1287, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[108, 68, 15644, 455, 14035, 2219, 120, 4403, ...</td>\n",
       "      <td>[2582, 1673, 1465, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[835, 835, 835, 112499, 7730, 523, 805, 530, 6...</td>\n",
       "      <td>[14397, 805, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[219, 8558, 13, 411, 353, 523, 7392, 1402, 156...</td>\n",
       "      <td>[41323, 434, 219, 805, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>[921, 138, 36, 1689, 156, 248, 179, 645, 1492,...</td>\n",
       "      <td>[6554, 156, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>[523, 1922, 219, 36, 1819, 10212, 34, 36, 317,...</td>\n",
       "      <td>[1922, 219, 523, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>[24044, 36, 214, 523, 987, 170, 539, 1465, 103...</td>\n",
       "      <td>[2271, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>[1465, 1916, 4104, 3710, 539, 2432, 58, 899, 5...</td>\n",
       "      <td>[3535, 539, 2082, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>[34, 807, 48, 3467, 4526, 102, 188, 203, 9974,...</td>\n",
       "      <td>[5476, 143, 1367, 1866, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reviewTexttokenized  \\\n",
       "0     [181, 5990, 36, 1089, 1465, 1465, 1594, 181, 4...   \n",
       "1     [117, 539, 1250, 413, 2025, 96, 45324, 32173, ...   \n",
       "2     [108, 68, 15644, 455, 14035, 2219, 120, 4403, ...   \n",
       "3     [835, 835, 835, 112499, 7730, 523, 805, 530, 6...   \n",
       "4     [219, 8558, 13, 411, 353, 523, 7392, 1402, 156...   \n",
       "...                                                 ...   \n",
       "2995  [921, 138, 36, 1689, 156, 248, 179, 645, 1492,...   \n",
       "2996  [523, 1922, 219, 36, 1819, 10212, 34, 36, 317,...   \n",
       "2997  [24044, 36, 214, 523, 987, 170, 539, 1465, 103...   \n",
       "2998  [1465, 1916, 4104, 3710, 539, 2432, 58, 899, 5...   \n",
       "2999  [34, 807, 48, 3467, 4526, 102, 188, 203, 9974,...   \n",
       "\n",
       "                                       summarytokenized  \n",
       "0     [1257, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [1287, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [2582, 1673, 1465, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [14397, 805, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [41323, 434, 219, 805, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "...                                                 ...  \n",
       "2995  [6554, 156, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2996  [1922, 219, 523, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2997  [2271, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2998  [3535, 539, 2082, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2999  [5476, 143, 1367, 1866, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f3a3e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_prob = []\n",
    "subpredict = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for row in subdf.iterrows():\n",
    "        logits, probas = model(torch.unsqueeze(torch.from_numpy(row[1]['reviewTexttokenized']), 0),\n",
    "                               torch.unsqueeze(torch.from_numpy(row[1]['summarytokenized']),0))\n",
    "        sub_prob.append(probas)\n",
    "        predict_levels = probas > 0.5\n",
    "        predicted_labels = torch.sum(predict_levels, dim=1)\n",
    "        lst = [str(int(i)+1) for i in predicted_labels]\n",
    "        subpredict.extend(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3080315",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pd.DataFrame(data=subpredict)\n",
    "outputdf.index.names = (['id'])\n",
    "outputdf.to_csv('submission_glove_Bilstm_cnn_ordinal_deep.csv', header = ['prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
